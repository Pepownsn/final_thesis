{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION EXPANDING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/11845055/predicting-from-previous-datevalue-data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # v. 1.7\n",
    "import MySQLdb\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "from sympy import *\n",
    "from sympy.solvers import solve\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import statistics \n",
    "\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import MySQLdb\n",
    "def initial_trend(series, slen):\n",
    "    sum = 0.0\n",
    "    for i in range(slen):\n",
    "        sum += float(series[i+slen] - series[i]) / slen\n",
    "    return sum / slen\n",
    "\n",
    "# >>> initial_trend(series, 12)\n",
    "# -0.7847222222222222\n",
    "\n",
    "def triple_exponential_smoothing(series, slen, alpha, beta, gamma, n_preds):\n",
    "    result = []\n",
    "    seasonals = initial_seasonal_components(series, slen)\n",
    "    for i in range(len(series)+n_preds):\n",
    "        if i == 0: # initial values\n",
    "            smooth = series[0]\n",
    "            trend = initial_trend(series, slen)\n",
    "            result.append(series[0])\n",
    "            continue\n",
    "        if i >= len(series): # we are forecasting\n",
    "            m = i - len(series) + 1\n",
    "            result.append((smooth + m*trend) + seasonals[i%slen])\n",
    "        else:\n",
    "            val = series[i]\n",
    "            last_smooth, smooth = smooth, alpha*(val-seasonals[i%slen]) + (1-alpha)*(smooth+trend)\n",
    "            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n",
    "            seasonals[i%slen] = gamma*(val-smooth) + (1-gamma)*seasonals[i%slen]\n",
    "            result.append(smooth+trend+seasonals[i%slen])\n",
    "    return result\n",
    "\n",
    "# # forecast 24 points (i.e. two seasons)\n",
    "# >>> triple_exponential_smoothing(series, 12, 0.716, 0.029, 0.993, 24)\n",
    "# [30, 20.34449316666667, 28.410051892109554, 30.438122252647577, 39.466817731253066, ...\n",
    "\n",
    "\n",
    "def initial_seasonal_components(series, slen):\n",
    "    seasonals = {}\n",
    "    season_averages = []\n",
    "    n_seasons = int(len(series)/slen)\n",
    "    # compute season averages\n",
    "    for j in range(n_seasons):\n",
    "        season_averages.append(sum(series[slen*j:slen*j+slen])/float(slen))\n",
    "    # compute initial values\n",
    "    for i in range(slen):\n",
    "        sum_of_vals_over_avg = 0.0\n",
    "        for j in range(n_seasons):\n",
    "            sum_of_vals_over_avg += series[slen*j+i]-season_averages[j]\n",
    "        seasonals[i] = sum_of_vals_over_avg/n_seasons\n",
    "    return seasonals\n",
    "##-----------------------------------------------------------------------------------\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def fittingparameter(data_y,j):\n",
    "    count_alpha = 0\n",
    "    count_beta = 0\n",
    "    count_gamma = 0\n",
    "    alpha = float(0)\n",
    "    beta = float(0)\n",
    "    gamma = float(0)\n",
    "    index_alpha =[]\n",
    "    index_beta =[]\n",
    "    index_gamma = []\n",
    "    act = j\n",
    "    data = data_y\n",
    "    pred_no = 1\n",
    "    ramda = 0.1\n",
    "    MSE_holtload = []\n",
    "#     query1 = \"SELECT active_power FROM prediction.data15min_4y WHERE Timestamp >= '%s' AND TimeStamp <= '%s';\"% (time_b[act+1],time_b[act+96])\n",
    "    query1 = \"SELECT total_watt FROM thesis.load WHERE Timestamp = '%s' ;\"% (time_b_last[act])\n",
    "    print query1\n",
    "    df1 = pd.read_sql(query1, conn)\n",
    "    while (alpha <= float(1)):\n",
    "        count_alpha += 1\n",
    "        beta = float(0)\n",
    "        while (beta <=float(1)):\n",
    "            count_beta += 1 \n",
    "            gamma = float(0)\n",
    "            while (gamma <= float(1)):\n",
    "                count_gamma += 1\n",
    "                pred_h = triple_exponential_smoothing(data, 96*7,alpha,beta ,gamma, pred_no)\n",
    "                pred_data = pred_h[len(pred_h)-(pred_no):]                                               \n",
    "                MSE = mean_squared_error (df1.total_watt, pred_data)   \n",
    "#                 print MSE              \n",
    "                MSE_holtload.append(MSE)\n",
    "                index_alpha.append(alpha)\n",
    "                index_beta.append(beta)\n",
    "                index_gamma.append(gamma)     \n",
    "#                 print index_alpha,index_beta,index_gamma\n",
    "                gamma += ramda\n",
    "            beta += ramda\n",
    "        alpha += ramda  \n",
    "#     print  count_gamma,count_beta,count_alpha    \n",
    "    index_MSE = MSE_holtload.index(min(MSE_holtload))\n",
    "#     print min(MSE_holtload)\n",
    "#     print index_MSE\n",
    "    MSE_min = MSE_holtload[index_MSE]\n",
    "    alpha = index_alpha[index_MSE]\n",
    "    beta = index_beta[index_MSE]\n",
    "    gamma= index_gamma[index_MSE]\n",
    "#     print count_alpha,count_beta,count_gamma\n",
    "    print MSE_min,alpha,beta,gamma\n",
    "    return (alpha,beta,gamma)\n",
    "\n",
    "\n",
    "def notify(msg):\n",
    "    URL = \"https://notify-api.line.me/api/notify\"\n",
    "    ACCESS_TOKEN = \"vxm278yAqFQcXbo2DlTbLD7pqO0QWU2McdNbiwhJWwp\"\n",
    "    MESSAGE_FIELD = {\"message\" : msg}\n",
    "    LINE_HEADERS = { \"Authorization\": \"Bearer \" + ACCESS_TOKEN }\n",
    "    try:\n",
    "        response = requests.post( url=URL,headers=LINE_HEADERS,data=MESSAGE_FIELD)\n",
    "#         print(\"Response HTTP Status Code: {status_code}\".format( status_code=response.status_code))\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"HTTP Request failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = MySQLdb.connect(\"localhost\",\"conn\",\"hems\")\n",
    "c = conn.cursor()\n",
    "query = \"SELECT Timestamp, total_watt FROM thesis.load WHERE Timestamp >= '%s'   AND TimeStamp <= '%s';\"% (\"2016-09-01 00:14:59\",\"2016-11-30 23:59:59\")\n",
    "df = pd.read_sql(query, conn , index_col=['Timestamp'])\n",
    "\n",
    "pred_no = 1 # power 1 Data/15min in 1Hr --> 60/15 = 4 and 1day = 4*24 = 96\n",
    "j = 0\n",
    "i = 0\n",
    "d = 31\n",
    "day =0\n",
    "\n",
    "conn = MySQLdb.connect(\"localhost\",\"conn\",\"hems\")\n",
    "c = conn.cursor()\n",
    "\n",
    "time_a = pd.date_range('2016-10-01 00:00:00', periods=96*d, freq='15T')\n",
    "time_b = pd.date_range('2016-10-01 00:14:59', periods=96*d, freq='15T')\n",
    "\n",
    "time_a_last = pd.date_range('2016-09-01 00:14:59', periods=96*d, freq='15T')\n",
    "time_b_last = pd.date_range('2016-09-30 23:59:59', periods=(96*d)+1, freq='15T')\n",
    "\n",
    "# set databases to empty \n",
    "query_empty = \"\"\"truncate table thesis.predict_expanding1\"\"\" \n",
    "c.execute(query_empty)\n",
    "\n",
    "while (j <= (96*d) -1) :    \n",
    "    if (j%96 == 0):    \n",
    "        day += 1\n",
    "        print \"________DAY:\" , day\n",
    "    \n",
    "    print \"\\ndata at :\" , j,\">>>\", time_b[j]\n",
    "    query_last = \"SELECT Timestamp,total_watt FROM  thesis.load WHERE Timestamp >= '%s'   AND TimeStamp <= '%s';\"% (time_a_last[0],time_b_last[j])\n",
    "    print query_last\n",
    "    df = pd.read_sql(query_last, conn)\n",
    "    conn.commit()\n",
    "    data_y = df['total_watt'].values.tolist()\n",
    "    ans_fiting = fittingparameter(data_y,j)\n",
    "    \n",
    "    query_last_new = \"SELECT Timestamp,total_watt FROM  thesis.load WHERE Timestamp>='%s'AND Timestamp<='%s';\"%(time_a_last[0],time_b_last[j])\n",
    "    query_last_new_1 = \"SELECT Timestamp,total_watt FROM  thesis.load  WHERE Timestamp = '%s' ;\"% (time_b_last[j+1])\n",
    "    print \"\\n\",query_last_new  \n",
    "    print query_last_new_1\n",
    "    print \"BY USE alpha =\",ans_fiting[0],\"beta =\",ans_fiting[1],\"gamma =\",ans_fiting[2]\n",
    "    df_last_new = pd.read_sql(query_last_new, conn)\n",
    "    conn.commit()\n",
    "    \n",
    "    data_y = df_last_new['total_watt'].values.tolist()     \n",
    "    pred_h = triple_exponential_smoothing(data_y, 96*7, ans_fiting[0], ans_fiting[1], ans_fiting[2],1)\n",
    "    pred_data = pred_h[len(pred_h)-(pred_no):]   \n",
    "    pred_watt = abs(pred_data[0])\n",
    "\n",
    "    c.execute(\"INSERT INTO thesis.predict_expanding1 (Timestamp, watt) VALUES ( %s, %s)\",(time_b[j],abs(pred_data[0])))\n",
    "    conn.commit()   \n",
    "    \n",
    "    if ( j == 0 or j == 500 or j == 1000 or j == 1500 or j == 2000 or j == 2500 or j == 2880):\n",
    "        notify(\"expand\")  \n",
    "        notify(j)  \n",
    "        \n",
    "    j += 1 \n",
    "print \"DONE!!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
